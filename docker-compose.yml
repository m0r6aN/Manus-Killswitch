services:
  redis:
    image: redis:7-alpine
    container_name: manus_redis
    ports:
      - "6379:6379"
    networks:
      - ai-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 3s
      retries: 30

  websocket-server:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_websocket_server
    command: uvicorn backend.main_websocket:app --host 0.0.0.0 --port 8000 --reload --reload-dir backend
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - LOGURU_LEVEL=DEBUG
    volumes:
      - ./backend:/app/backend
    networks:
      - ai-network
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

  tools-agent:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_tools_agent
    command: uvicorn backend.main_tools_agent:app --host 0.0.0.0 --port 8001 --reload --reload-dir backend
    ports:
      - "8001:8001"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - DATABASE_URL=sqlite+aiosqlite:///app/backend/agents/tools_agent/db/toolstore.db # In-container path
      - LOGURU_LEVEL=DEBUG
      - TOOLS_DIR=/app/backend/agents/tools_agent/tools # Execution path inside container
    volumes:
      - ./backend:/app/backend # Mount backend code
      # Volume to persist the DB outside the container
      - toolstore_db:/app/backend/agents/tools_agent/db
      # Mount local tools dir into the container at the expected path
      - ./backend/agents/tools_agent/tools:/app/backend/agents/tools_agent/tools
    networks:
      - ai-network
    depends_on:
      - redis
    restart: unless-stopped
    # Simple healthcheck: check if the API is responding
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  grok-agent:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_grok_agent
    command: python backend/main_grok_agent.py
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - AGENT_NAME=grok
      - LOGURU_LEVEL=DEBUG
      - TOOLS_API_URL=http://tools-agent:8001
    volumes:
      - ./backend:/app/backend
    networks:
      - ai-network
    depends_on:
      - redis
      - websocket-server # Wait for WS server, though comms are via Redis
      - tools-agent # Depends on ToolCore API being available
    restart: unless-stopped

  claude-agent:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_claude_agent
    command: python -m backend.main_websocket # Use module path, no --reload with -m usually
    #command: python backend/main_claude_agent.py
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - AGENT_NAME=claude
      - LOGURU_LEVEL=DEBUG
      - TOOLS_API_URL=http://tools-agent:8001
    volumes:
      - ./backend:/app/backend
    networks:
      - ai-network
    depends_on:
      - redis
      - websocket-server
      - tools-agent
    restart: unless-stopped

  gpt-agent:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_gpt_agent
    command: python backend/main_gpt_agent.py
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - AGENT_NAME=gpt
      - LOGURU_LEVEL=DEBUG
      - TOOLS_API_URL=http://tools-agent:8001
    volumes:
      - ./backend:/app/backend
    networks:
      - ai-network
    depends_on:
      - redis
      - websocket-server
      - tools-agent
    restart: unless-stopped

  codex-agent:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_codex_agent
    command: python backend/main_codex_agent.py
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - AGENT_NAME=codex # Set specifically if needed, though agent reads from config
      - CODEX_AGENT_NAME=codex # Ensure config setting is passed if needed
      - CODEX_API_KEY=${CODEX_API_KEY:-YOUR_CODEX_LLM_API_KEY_HERE} # Use env var or default
      - LOGURU_LEVEL=DEBUG
      - TOOLS_API_URL=http://tools-agent:8001
    volumes:
      - ./backend:/app/backend
    networks:
      - ai-network
    depends_on:
      - redis
      - websocket-server
      - tools-agent # May need tools? Unlikely for workflow gen.
      - grok-agent # Depends on orchestrator conceptually
    restart: unless-stopped

  coordinator-agent:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_coordinator_agent
    command: python backend/main_coordinator_agent.py
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - COORDINATOR_AGENT_NAME=coordinator # Pass from config.py via settings
      - LOGURU_LEVEL=DEBUG
      # No external API keys needed typically
    volumes:
      - ./backend:/app/backend
    networks:
      - ai-network
    depends_on:
      # Depends only on Redis being up to start monitoring
      redis:
        condition: service_healthy
      # Doesn't strictly depend on other agents being up, as its job *is* to wait for them
    restart: unless-stopped

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    container_name: manus_frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_WS_URL=ws://localhost:8000/ws # Connect to host machine's mapped port
      # Use this if running frontend locally and backend in docker:
      # - NEXT_PUBLIC_WS_URL=ws://localhost:8000/ws
      # Use this for frontend container talking to backend container (requires modification in useWebSocket hook):
      # - NEXT_PUBLIC_WS_URL=ws://websocket-server:8000/ws
    volumes:
      - ./frontend:/app # Mount code for hot-reloading (if using dev)
      - /app/node_modules # Don't mount host node_modules
      - /app/.next
    networks:
      - ai-network
    depends_on:
      - websocket-server
    restart: unless-stopped

networks:
  ai-network:
    driver: bridge

volumes:
  toolstore_db: # Define the named volume for the SQLite DB