services:
  redis:
    image: redis:7-alpine
    container_name: manus_redis
    ports:
      - "6379:6379"
    networks:
      - ai-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 3s
      retries: 30

  websocket-server:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_websocket_server
    command: uvicorn backend.main_websocket:app --host 0.0.0.0 --port 8000 --reload --reload-dir backend
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - LOGURU_LEVEL=DEBUG
    volumes:
      - ./backend:/app/backend
    networks:
      - ai-network
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

   # Python Sandbox Executor
  sandbox-executor:
    build:
      context: ./sandbox-executor
      dockerfile: Dockerfile
    ports:
      - "8001:8000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock  # Mount Docker socket
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=INFO
    networks:
      - task-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # Tool Core API
  tool-core:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8002:8000"
    depends_on:
      - redis
      - sandbox-executor
    environment:
      - REDIS_URL=redis://redis:6379
      - SANDBOX_API_URL=http://sandbox-executor:8000
      - LOG_LEVEL=INFO
    networks:
      - task-network
    restart: unless-stopped

  # Task Manager API
  task-manager:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8003:8000"
    depends_on:
      - redis
      - tool-core
    environment:
      - REDIS_URL=redis://redis:6379
      - TOOL_API_URL=http://tool-core:8000
      - LOG_LEVEL=INFO
    networks:
      - task-network
    restart: unless-stopped

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    depends_on:
      - task-manager
      - tool-core
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8003
      - NEXT_PUBLIC_TOOL_API_URL=http://localhost:8002
    networks:
      - task-network
    restart: unless-stopped

  tools-agent:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_tools_agent
    command: uvicorn backend.main_tools_agent:app --host 0.0.0.0 --port 8001 --reload --reload-dir backend
    ports:
      - "8001:8001"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - DATABASE_URL=sqlite+aiosqlite:///app/backend/agents/tools_agent/db/toolstore.db # In-container path
      - LOGURU_LEVEL=DEBUG
      - TOOLS_DIR=/app/backend/agents/tools_agent/tools # Execution path inside container
    volumes:
      - ./backend:/app/backend # Mount backend code
      # Volume to persist the DB outside the container
      - toolstore_db:/app/backend/agents/tools_agent/db
      # Mount local tools dir into the container at the expected path
      - ./backend/agents/tools_agent/tools:/app/backend/agents/tools_agent/tools
    networks:
      - ai-network
    depends_on:
      - redis
    restart: unless-stopped
    # Simple healthcheck: check if the API is responding
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  grok-agent:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_grok_agent
    command: python -m backend.main_grok_agent
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - AGENT_NAME=${GROK_AGENT_NAME}
      - AGENT_API_KEY=${GROK_API_KEY}
      - API_BASE=${GROK_API_BASE}
      - API_VERSION=${GROK_API_VERSION}
      - LLM_MODEL=${GROK_MODEL}
      - LOGURU_LEVEL=DEBUG
      - TOOLS_API_BASE=http://tools-agent:8001
    volumes:
      - ./backend:/app/backend
    networks:
      - ai-network
    depends_on:
      - redis
      - websocket-server # Wait for WS server, though comms are via Redis
      - tools-agent # Depends on ToolCore API being available
    restart: unless-stopped

  claude-agent:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_claude_agent
    command: python -m backend.main_claude_agent
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - AGENT_NAME=${GPT_AGENT_NAME}
      - AGENT_API_KEY=${ANTHROPIC_API_KEY}
      - API_BASE=${ANTHROPIC_API_BASE}
      - API_VERSION=${ANTHROPIC_API_VERSION}
      - LLM_MODEL=${CLAUDE_MODEL}
      - LOGURU_LEVEL=DEBUG
      - TOOLS_API_BASE=http://tools-agent:8001
    volumes:
      - ./backend:/app/backend
    networks:
      - ai-network
    depends_on:
      - redis
      - websocket-server
      - tools-agent
    restart: unless-stopped

  gpt-agent:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_gpt_agent
    command: python -m backend.main_gpt_agent
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - AGENT_NAME=${GPT_AGENT_NAME}
      - AGENT_API_KEY=${OPENAI_API_KEY}
      - API_BASE=${OPENAI_API_BASE}
      - API_VERSION=${OPENAI_API_VERSION}
      - LLM_MODEL=${GPT_MODEL}
      - LOGURU_LEVEL=DEBUG
      - TOOLS_API_BASE=http://tools-agent:8001
    volumes:
      - ./backend:/app/backend
    networks:
      - ai-network
    depends_on:
      - redis
      - websocket-server
      - tools-agent
    restart: unless-stopped

  codex-agent:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_codex_agent
    command: python -m backend.main_codex_agent
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - AGENT_NAME=${CODEX_AGENT_NAME}
      - LOGURU_LEVEL=DEBUG
    volumes:
      - ./backend:/app/backend
    networks:
      - ai-network
    depends_on:
      redis:
        condition: service_healthy
      # Doesn't strictly depend on other agents being up, as its job *is* to wait for them
    restart: unless-stopped

  coordinator-agent:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: manus_coordinator_agent
    command: python -m backend.main_coordinator_agent
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - AGENT_NAME=${COORDINATOR_AGENT_NAME}
      - LOGURU_LEVEL=DEBUG
    volumes:
      - ./backend:/app/backend
    networks:
      - ai-network
    depends_on:
      redis:
        condition: service_healthy
      # Doesn't strictly depend on other agents being up, as its job *is* to wait for them
    restart: unless-stopped

  # frontend:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.frontend
  #   container_name: manus_frontend
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     - NEXT_PUBLIC_WS_URL=ws://localhost:8000/ws # Connect to host machine's mapped port
  #     # Use this if running frontend locally and backend in docker:
  #     # - NEXT_PUBLIC_WS_URL=ws://localhost:8000/ws
  #     # Use this for frontend container talking to backend container (requires modification in useWebSocket hook):
  #     # - NEXT_PUBLIC_WS_URL=ws://websocket-server:8000/ws
  #   volumes:
  #     - ./frontend:/app # Mount code for hot-reloading (if using dev)
  #     - /app/node_modules # Don't mount host node_modules
  #     - /app/.next
  #   networks:
  #     - ai-network
  #   depends_on:
  #     - websocket-server
  #   restart: unless-stopped

networks:
  ai-network:
    driver: bridge

volumes:
  toolstore_db: # Define the named volume for the SQLite DB